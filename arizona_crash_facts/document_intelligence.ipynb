{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install azure-ai-formrecognizer azure-ai-documentintelligence pdf2image python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "\n",
    "endpoint = \"https://aadt-di.cognitiveservices.azure.com/\"\n",
    "key = \"DFyaCCztV1k9XvIzB0GJXvnjblEvOP8PF7o9rfDdbF7V3uAYU2jiJQQJ99BBACYeBjFXJ3w3AAALACOGYJH0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "images = convert_from_path(\"data/2023-Crash-Facts_0.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def pil_to_base64(image: Image.Image, format=\"PNG\") -> str:\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=format)\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest, DocumentContentFormat, AnalyzeResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown = \"\"\n",
    "\n",
    "for img in images:\n",
    "    document_intelligence_client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-layout\",\n",
    "        AnalyzeDocumentRequest(bytes_source=pil_to_base64(img)),\n",
    "        output_content_format=DocumentContentFormat.MARKDOWN,\n",
    "    )\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    markdown += result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output_document_intelligence/raw_output.md\", \"w\") as f:\n",
    "    f.write(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_text = \"\"\n",
    "\n",
    "with open(\"output_document_intelligence/raw_output.md\", \"r\") as file:\n",
    "    entire_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_figure_tags(text):\n",
    "    return re.sub(r\"<figure>.*?</figure>\", \"\", text, flags=re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = remove_figure_tags(entire_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output_document_intelligence/cleaned_output.md\", \"w\") as f:\n",
    "    f.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to manually remove\n",
    "\n",
    "- Initial few pages for TOC etc\n",
    "- Need to set captions properly for few tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use LLM to make a summary of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output_document_intelligence/cleaned_output.md\", \"r\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into tables and text\n",
    "tables = []\n",
    "text = []\n",
    "over_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data by <table> tags\n",
    "parts = data.split(\"<table>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in parts:\n",
    "    if \"</table>\" in part:\n",
    "        # Extract the table content\n",
    "        table_content = part.split(\"</table>\")[0]\n",
    "        tables.append(f\"<table>{table_content}</table>\")\n",
    "        over_all.append(f\"<table>{table_content}</table>\")\n",
    "        # Add any text after the table\n",
    "        remaining_text = part.split(\"</table>\")[1].strip()\n",
    "        if remaining_text:\n",
    "            text.append(remaining_text)\n",
    "            over_all.append(remaining_text)\n",
    "    else:\n",
    "        # Add text that is not part of a table\n",
    "        if part.strip():\n",
    "            text.append(part.strip())\n",
    "            over_all.append(part.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: 96\n",
      "Text: 52\n",
      "Overall: 148\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tables: {len(tables)}\")\n",
    "print(f\"Text: {len(text)}\")\n",
    "print(f\"Overall: {len(over_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarized_data = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_summary_mapping = {}\n",
    "\n",
    "# prompt = \"Provide me a single paragraph that explains the table which can be used as a metadata. Do not provide any data details or anything that can be retrieved as information from the table itself. Just a summary of the table. Make sure you dont mention any table number or any other information that can be used to identify the table.\"\n",
    "\n",
    "prompt = \"Given the table below, provide a summary of the table. Make sure you dont mention any table number. Provide details about what the table is about, but do not provide any data details or anything that can be retrieved as information from the table itself.\"\n",
    "\n",
    "for idx, table in enumerate(tables):\n",
    "    summarized_text = llm.invoke(table + \"\\n\\n\" + prompt)\n",
    "    table_summary_mapping[table] = summarized_text.content\n",
    "    summarized_data += f\"Table {idx + 1}:\\n\\n{summarized_text.content}\\n\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output_document_intelligence/summarized_tables_prompt2.md\", \"w\") as file:\n",
    "    file.write(summarized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
